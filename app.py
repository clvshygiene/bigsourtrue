import streamlit as st
import pandas as pd
from datetime import datetime
import io
from docx import Document # ç”¨ä¾†ç”¢å‡º Word
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn

# --- é é¢è¨­å®š ---
st.set_page_config(page_title="æ ¡åœ’æƒå€æª¢æ ¸ç³»çµ±", page_icon="ğŸ§¹", layout="centered")
st.title("ğŸ§¹ 114-2 æ ¡åœ’å¤§æƒé™¤æª¢æ ¸ç³»çµ±")

# --- 1. è®€å–è³‡æ–™å‡½å¼ ---
@st.cache_data(ttl=600)
def load_data():
    try:
        # ğŸ‘‡ è«‹ç¢ºèªé€™è£¡å¡«å¯«çš„æ˜¯æ­£ç¢ºçš„ Google è©¦ç®—è¡¨é€£çµ
        google_sheet_url = "https://docs.google.com/spreadsheets/d/1jqpj-DOe1X2cf6cToWmtW19_0FdN3REioa34aXn4boA/edit?usp=sharing"
        
        # è‡ªå‹•è½‰æ›ç‚º Excel ä¸‹è¼‰é€£çµ
        if "/edit" in google_sheet_url:
            excel_url = google_sheet_url.replace("/edit", "/export?format=xlsx")
            excel_url = excel_url.split("?")[0] + "?format=xlsx"
        else:
            excel_url = google_sheet_url

        # è®€å– Excel
        all_sheets = pd.read_excel(excel_url, sheet_name=None, dtype=str)
        
        # æª¢æŸ¥å¿…è¦åˆ†é 
        required_sheets = ['ç­ç´šæ¸…å–®', 'åœ°é»è³‡æ–™åº«', 'æƒå€åˆ†é…ç¸½è¡¨', 'æª¢æŸ¥æ¨™æº–']
        for sheet in required_sheets:
            if sheet not in all_sheets:
                st.error(f"âŒ æ‰¾ä¸åˆ°å·¥ä½œè¡¨ï¼šã€Œ{sheet}ã€")
                return None, None, None

        df_classes = all_sheets['ç­ç´šæ¸…å–®']
        df_locations = all_sheets['åœ°é»è³‡æ–™åº«']
        df_assign = all_sheets['æƒå€åˆ†é…ç¸½è¡¨']
        df_standards = all_sheets['æª¢æŸ¥æ¨™æº–']
        
        # è³‡æ–™åˆä½µ
        df_full = pd.merge(df_assign, df_locations, on='åœ°é»ID', how='left')
        df_full = pd.merge(df_full, df_classes, left_on='è² è²¬ç­ç´š', right_on='ç­ç´šä»£ç¢¼', how='left')
        df_full = df_full.dropna(subset=['è² è²¬ç­ç´š'])
        
        return df_classes, df_full, df_standards
        
    except Exception as e:
        st.error("âŒ è³‡æ–™è®€å–å¤±æ•—ï¼")
        return None, None, None

# --- 2. ç”¢ç”Ÿ Word æ–‡ä»¶çš„å‡½å¼ ---
def generate_docx(class_name, tasks_df, standards_df):
    doc = Document()
    
    # è¨­å®šä¸­æ–‡å­—å‹ (é€™æ˜¯è®“ Word é¡¯ç¤ºæ¨™æ¥·é«”æˆ–æ–°ç´°æ˜é«”çš„é—œéµ)
    style = doc.styles['Normal']
    style.font.name = 'Times New Roman'
    style.element.rPr.rFonts.set(qn('w:eastAsia'), 'æ¨™æ¥·é«”')
    
    # æ¨™é¡Œ
    title = doc.add_heading(f'{class_name} å¤§æƒé™¤æª¢æ ¸è¡¨', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    p = doc.add_paragraph()
    p.add_run(f"åˆ—å°æ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d')}\n").bold = True
    p.alignment = WD_ALIGN_PARAGRAPH.RIGHT

    # æº–å‚™æ¨™æº–å­—å…¸
    standards_grouped = standards_df.groupby('æª¢æŸ¥é¡å‹')

    # éæ­·ä»»å‹™
    for index, row in tasks_df.iterrows():
        # åœ°é»åç¨±
        bldg = str(row['å¤§æ¨“']) if pd.notna(row['å¤§æ¨“']) else ""
        floor = str(row['æ¨“å±¤']) if pd.notna(row['æ¨“å±¤']) else ""
        detail = str(row['è©³ç´°ä½ç½®']) if pd.notna(row['è©³ç´°ä½ç½®']) else ""
        full_name = f"{bldg} {floor} {detail}".strip()
        
        # åŠ å…¥åœ°é»æ¨™é¡Œ
        doc.add_heading(f"ğŸ“ {full_name}", level=2)
        
        # æ³¨æ„äº‹é …
        note = row['ç‰¹åˆ¥æ³¨æ„äº‹é …']
        if pd.notna(note) and str(note).strip() != "":
            p = doc.add_paragraph()
            run = p.add_run(f"âš ï¸ æ³¨æ„ï¼š{note}")
            run.font.color.rgb = pd.io.common.colors.RGB(255, 0, 0) # ç´…è‰²å­—
        
        # å»ºç«‹æª¢æŸ¥è¡¨æ ¼
        check_type = row['æª¢æŸ¥é¡å‹']
        if check_type in standards_grouped.groups:
            type_df = standards_grouped.get_group(check_type)
            
            # å»ºç«‹è¡¨æ ¼ (å¯¬åº¦è‡ªå‹•èª¿æ•´)
            table = doc.add_table(rows=1, cols=3)
            table.style = 'Table Grid'
            hdr_cells = table.rows[0].cells
            hdr_cells[0].text = 'å­åˆ†é¡'
            hdr_cells[1].text = 'æª¢æŸ¥é …ç›®'
            hdr_cells[2].text = 'æª¢æŸ¥ç¢ºèª(æ‰“å‹¾)'
            
            # å¡«å…¥è³‡æ–™
            if 'å­åˆ†é¡' in type_df.columns:
                # ä¾ç…§å­åˆ†é¡æ’åº
                type_df_sorted = type_df.sort_values(by=['å­åˆ†é¡'], na_position='first')
                for item_row in type_df_sorted.itertuples():
                    row_cells = table.add_row().cells
                    sub_cat = str(item_row.å­åˆ†é¡) if pd.notna(item_row.å­åˆ†é¡) else "-"
                    row_cells[0].text = sub_cat
                    row_cells[1].text = item_row.æª¢æŸ¥ç´°é …
                    row_cells[2].text = "â–¡"
            else:
                 for item_row in type_df.itertuples():
                    row_cells = table.add_row().cells
                    row_cells[0].text = "-"
                    row_cells[1].text = item_row.æª¢æŸ¥ç´°é …
                    row_cells[2].text = "â–¡"
        else:
            doc.add_paragraph(f"(æœªæ‰¾åˆ°é¡å‹ {check_type} çš„æª¢æŸ¥æ¨™æº–)")
            
        doc.add_paragraph("\n") # ç©ºè¡Œ

    # --- ç°½åå€å¡Š ---
    doc.add_page_break() # ç°½åé æˆ–æ”¾åœ¨æœ€ä¸‹é¢
    doc.add_heading("ç°½åç¢ºèªå€", level=1)
    
    sig_table = doc.add_table(rows=3, cols=2)
    sig_table.style = 'Table Grid'
    
    # èª¿æ•´è¡¨æ ¼é«˜åº¦
    for row in sig_table.rows:
        row.height = Inches(0.8)
    
    # å¡«å¯«å…§å®¹
    sig_table.cell(0, 0).text = "è¡›ç”Ÿè‚¡é•· (1)"
    sig_table.cell(0, 1).text = "è¡›ç”Ÿè‚¡é•· (2)"
    sig_table.cell(1, 0).text = "è¡›ç”Ÿç³¾å¯Ÿ (1)"
    sig_table.cell(1, 1).text = "è¡›ç”Ÿç³¾å¯Ÿ (2)"
    sig_table.cell(2, 0).text = "å°å¸«ç°½å"
    # åˆä½µå°å¸«æ¬„ä½
    a = sig_table.cell(2, 0)
    b = sig_table.cell(2, 1)
    a.merge(b)

    return doc

# --- ä¸»ç¨‹å¼ ---
df_classes, df_tasks, df_standards = load_data()

if df_tasks is not None:
    st.sidebar.header("ğŸ“ ç­ç´šç™»å…¥")
    
    # å´é‚Šæ¬„é‚è¼¯
    if 'å¹´ç´š' in df_classes.columns:
        all_grades = sorted(df_classes['å¹´ç´š'].astype(str).unique())
        selected_grade = st.sidebar.selectbox("è«‹é¸æ“‡å¹´ç´š", all_grades)
        classes_filter = df_classes[df_classes['å¹´ç´š'] == selected_grade]
    else:
        st.error("ç­ç´šæ¸…å–®ç¼ºå°‘ã€Œå¹´ç´šã€æ¬„ä½")
        st.stop()
    
    class_options = {
        f"{row['ç­ç´šä»£ç¢¼']} - {row['é¡¯ç¤ºåç¨±']}": row['ç­ç´šä»£ç¢¼'] 
        for index, row in classes_filter.iterrows()
    }
    
    if not class_options:
        st.stop()

    selected_option = st.sidebar.selectbox("è«‹é¸æ“‡ç­ç´š", list(class_options.keys()))
    current_class_id = class_options[selected_option]
    current_class_name = selected_option.split(" - ")[-1] # å–å¾—ç­ç´šåç¨± (å¦‚ é¤é£²ç§‘)

    # ä¸»ç•«é¢
    st.info(f"ğŸ‘‹ æ­¡è¿ **{selected_option}**")
    
    my_tasks = df_tasks[df_tasks['è² è²¬ç­ç´š'] == current_class_id]
    
    # --- Word ä¸‹è¼‰æŒ‰éˆ• ---
    if not my_tasks.empty:
        st.markdown("### ğŸ–¨ï¸ ç´™æœ¬æª¢æ ¸è¡¨ä¸‹è¼‰")
        st.write("é»æ“Šä¸‹æ–¹æŒ‰éˆ•ä¸‹è¼‰ Word æª”ï¼Œå°å‡ºå¾Œå®Œæˆç°½åã€‚")
        
        # ç”¢ç”Ÿ Word æª”ä¸¦å­˜å…¥è¨˜æ†¶é«”
        doc = generate_docx(selected_option, my_tasks, df_standards)
        bio = io.BytesIO()
        doc.save(bio)
        
        st.download_button(
            label="ğŸ“¥ ä¸‹è¼‰ Word æª¢æ ¸è¡¨ (.docx)",
            data=bio.getvalue(),
            file_name=f"{selected_option}_å¤§æƒé™¤æª¢æ ¸è¡¨.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
        )
        st.markdown("---")

    # --- æ•¸ä½é è¦½å€ (å·²ä¿®å¾© key é‡è¤‡å•é¡Œ) ---
    st.markdown("### ğŸ“± æ•¸ä½é è¦½ (åƒ…ä¾›åƒè€ƒ)")
    standards_grouped = df_standards.groupby('æª¢æŸ¥é¡å‹')

    if my_tasks.empty:
        st.warning("ç›®å‰ç„¡åˆ†é…æƒå€ã€‚")
    else:
        with st.form(key='preview_form'):
            for index, row in my_tasks.iterrows():
                bldg = row['å¤§æ¨“'] if pd.notna(row['å¤§æ¨“']) else ""
                floor = row['æ¨“å±¤'] if pd.notna(row['æ¨“å±¤']) else ""
                detail = row['è©³ç´°ä½ç½®'] if pd.notna(row['è©³ç´°ä½ç½®']) else ""
                full_name = f"{bldg} {floor} {detail}".strip()
                
                check_type = row['æª¢æŸ¥é¡å‹']
                note = row['ç‰¹åˆ¥æ³¨æ„äº‹é …']
                location_id = row['åœ°é»ID']
                
                st.subheader(f"ğŸ“ {full_name}")
                if pd.notna(note) and str(note).strip() != "":
                    st.warning(f"æ³¨æ„ï¼š{note}")
                
                if check_type in standards_grouped.groups:
                    type_df = standards_grouped.get_group(check_type)
                    
                    if 'å­åˆ†é¡' in type_df.columns:
                        sub_groups = type_df.groupby('å­åˆ†é¡', sort=False)
                        for sub_cat, items_df in sub_groups:
                            if pd.notna(sub_cat):
                                st.markdown(f"**ğŸ”¹ {sub_cat}**")
                            
                            cols = st.columns(2)
                            # ğŸ”¹ é€™è£¡åŠ å…¥äº†å…¨åŸŸ index ä¾†ä¿è­‰ Key çµ•å°å”¯ä¸€
                            for idx, item_row in enumerate(items_df.itertuples()):
                                # Key æ ¼å¼ï¼šç­ç´š_åœ°é»_å­åˆ†é¡_é …ç›®_ç´¢å¼•
                                # é€™æ¨£å°±ç®—é …ç›®åç¨±å®Œå…¨ä¸€æ¨£ï¼Œä¹Ÿä¸æœƒé‡è¤‡
                                unique_key = f"{current_class_id}_{location_id}_{sub_cat}_{item_row.æª¢æŸ¥ç´°é …}_{idx}"
                                with cols[idx % 2]:
                                    st.checkbox(item_row.æª¢æŸ¥ç´°é …, key=unique_key)
                            st.write("")
                    else:
                        for idx, item_row in enumerate(type_df.itertuples()):
                             unique_key = f"{current_class_id}_{location_id}_{item_row.æª¢æŸ¥ç´°é …}_{idx}"
                             st.checkbox(item_row.æª¢æŸ¥ç´°é …, key=unique_key)
                
                st.markdown("---")
            

            st.form_submit_button("æ•¸ä½é€å‡º (æ¸¬è©¦ç”¨)")
